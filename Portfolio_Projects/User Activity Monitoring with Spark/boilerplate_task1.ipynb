{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoilerPlate Task 1 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Initialize the SparkSession\n",
    "# The SparkSession is the entry point to Spark functionality.\n",
    "spark = ( SparkSession.builder \n",
    "    .appName(\"QuickCommerce Streaming Pipeline\") \n",
    "    # Set a descriptive application name\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\")  \n",
    "    # Include Kafka package\n",
    "    .getOrCreate())\n",
    "\n",
    "# Step 2: Read from the Kafka topic\n",
    "# Configure the Kafka connection and subscribe to the desired topic.\n",
    "streaming_df = (spark.readStream \n",
    "    .format(\"kafka\")  \n",
    "# Specify Kafka as the data source\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")  \n",
    " # Kafka server address\n",
    "    .option(\"subscribe\", \"ecommerce_topic\") \n",
    " # Topic to read data from\n",
    "    .load())\n",
    "\n",
    "# Step 3: Define the checkpoint directory\n",
    "# The checkpoint directory is used to ensure fault tolerance.\n",
    "checkpoint_dir = \"/tmp/quickcommerce_streaming_checkpoint\"\n",
    "\n",
    "# Step 4: Write the streaming data to the console\n",
    "# Display the incoming data in the console for testing.\n",
    "query = (streaming_df.writeStream \\\n",
    "    .format(\"console\") \n",
    " # Output the data to the console\n",
    "    .outputMode(\"append\") \n",
    "  # Display only the new data that arrives\n",
    "    .option(\"checkpointLocation\", checkpoint_dir) \n",
    "  # Enable checkpointing for fault tolerance\n",
    "    .start())\n",
    "\n",
    "# Step 5: Print the schema of the streaming DataFrame\n",
    "# Display the structure of the incoming data for reference.\n",
    "streaming_df.printSchema()\n",
    "\n",
    "# Keep the application running until manually terminated.\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
